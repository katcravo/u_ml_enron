{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "%matplotlib notebook\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import my_data_utils\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] \n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max salary TOTAL 26704229\n",
      "remove max\n",
      "Max salary SKILLING JEFFREY K 1111258\n"
     ]
    }
   ],
   "source": [
    "def maxPrinter(data_dict, sub_field):\n",
    "    sub_dict = {key:data_dict[key][sub_field] for key in data_dict if data_dict[key][sub_field] != 'NaN'}\n",
    "    max_key = max(sub_dict, key=sub_dict.get)\n",
    "    print \"Max\", sub_field, max_key, sub_dict[ max_key ]\n",
    "\n",
    "def removeMax(data_dict, sub_field):\n",
    "    sub_dict = {key:data_dict[key][sub_field] for key in data_dict if data_dict[key][sub_field] != 'NaN'}\n",
    "    max_val = max(sub_dict, key=sub_dict.get) \n",
    "    data_dict.pop(max_val, 0)\n",
    "\n",
    "maxPrinter(data_dict, 'salary')\n",
    "print 'remove max'\n",
    "removeMax(data_dict, 'salary')\n",
    "maxPrinter(data_dict, 'salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "#email_to_poi_ratio\n",
    "#email_from_poi_ratio\n",
    "for key in data_dict.keys():\n",
    "    email_to = data_dict[key]['to_messages']\n",
    "    to_poi = data_dict[key]['from_this_person_to_poi']\n",
    "    email_from = data_dict[key]['from_messages']\n",
    "    from_poi = data_dict[key]['from_poi_to_this_person']\n",
    "    exer_stock_opt = data_dict[key]['exercised_stock_options']\n",
    "    total_stock = data_dict[key]['total_stock_value']\n",
    "    \n",
    "    if 'NaN' not in (email_to, to_poi):\n",
    "        data_dict[key]['email_to_poi_ratio'] = float(to_poi)/float(email_to)\n",
    "    else:\n",
    "        data_dict[key]['email_to_poi_ratio'] = 'NaN'\n",
    "    if 'NaN' not in (email_from, from_poi):\n",
    "        data_dict[key]['email_from_poi_ratio'] = float(from_poi)/float(email_from)\n",
    "    else:\n",
    "        data_dict[key]['email_from_poi_ratio'] = 'NaN'\n",
    "    if 'NaN' not in (exer_stock_opt, total_stock):\n",
    "        data_dict[key]['exer_stock_ratio'] = float(exer_stock_opt)/float(total_stock)\n",
    "    else:\n",
    "        data_dict[key]['exer_stock_ratio'] = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_k_fold_test_short (classifier, features, labels, kval=10):\n",
    "    from sklearn.model_selection import KFold\n",
    "    k_fold = KFold(kval)\n",
    "\n",
    "    #print \"Iteration: precision, recall, f1\"\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for k, (train, test) in enumerate(k_fold.split(features, labels)):\n",
    "        scores = scoreClassifier (classifier,\n",
    "                                     [features[ii] for ii in train], [features[ii] for ii in test],\n",
    "                                     [labels[ii] for ii in train], [labels[ii] for ii in test]) \n",
    "        #print \"#\", k,\":\", scores\n",
    "        precision.append(scores[0])\n",
    "        recall.append(scores[1])\n",
    "        f1.append(scores[2])\n",
    "    avPrecision = sum(precision)/kval\n",
    "    avRecall = sum(recall)/kval\n",
    "    avF1 = sum(f1)/kval\n",
    "    print 'Precision', avPrecision, ', Recall', avRecall, ', F1', avF1\n",
    "\n",
    "def scoreClassifier(classifier, features_train, features_test, labels_train, labels_test):\n",
    "    from sklearn import metrics\n",
    "    classifier.fit(features_train, labels_train)\n",
    "    test_pred = classifier.predict(features_test)\n",
    "    precision = metrics.precision_score(labels_test, test_pred)\n",
    "    recall = metrics.recall_score(labels_test, test_pred)  \n",
    "    f1 = metrics.f1_score(labels_test, test_pred)\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++\n",
      "Returning best Grid Search Decision Tree Classifier\n",
      "Features: ['poi', 'other', 'expenses', 'total_stock_value', 'exercised_stock_options', 'long_term_incentive', 'from_this_person_to_poi', 'from_messages', 'restricted_stock']\n",
      "Precision 0.341666666667 , Recall 0.825 , F1 0.444047619048\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "def get_best_decision_tree(data_dict, features_list):\n",
    "    print \"+++++++++++++++++++++++++++++++++++++\"\n",
    "    print \"Returning best Grid Search Decision Tree Classifier\"\n",
    "    print 'Features:', features_list\n",
    "    my_dataset = data_dict\n",
    "    data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)    \n",
    "    ### base test/train split for simple \n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state=42, stratify=labels)\n",
    "\n",
    "    # Set up cross validator (will be used for tuning all classifiers)\n",
    "    from sklearn import cross_validation\n",
    "    cv = cross_validation.StratifiedShuffleSplit(labels_train, test_size=.1, random_state = 42)\n",
    "\n",
    "    ### Test Decision Trees \n",
    "    from sklearn import tree\n",
    "    parameters = {'max_depth':[2,3,5,8,10,15], 'min_samples_split':[2,3,5], 'criterion' : ['gini','entropy'],\n",
    "                  'class_weight': [{True: 12, False: 1}, {True: 4, False: 1}, 'auto', None]}\n",
    "    tempDTClf = tree.DecisionTreeClassifier()\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    gridClf = GridSearchCV(tempDTClf, parameters, scoring='f1', cv=cv)\n",
    "    best_dt = gridClf.fit(features_train, labels_train).best_estimator_\n",
    "    my_k_fold_test_short(best_dt, features, labels)\n",
    "    return best_dt\n",
    "\n",
    "features_list_importance = ['poi', 'other', 'expenses', 'total_stock_value', 'exercised_stock_options',\n",
    "                            'long_term_incentive', 'from_this_person_to_poi', 'from_messages', 'restricted_stock']    \n",
    "best_dt = get_best_decision_tree(data_dict, features_list_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(best_dt, data_dict, features_list_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/pickle\n",
    "\n",
    "\"\"\" a basic script for importing student's POI identifier,\n",
    "    and checking the results that they get from it \n",
    " \n",
    "    requires that the algorithm, dataset, and features list\n",
    "    be written to my_classifier.pkl, my_dataset.pkl, and\n",
    "    my_feature_list.pkl, respectively\n",
    "\n",
    "    that process should happen at the end of poi_id.py\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n",
    "\n",
    "CLF_PICKLE_FILENAME = \"my_classifier.pkl\"\n",
    "DATASET_PICKLE_FILENAME = \"my_dataset.pkl\"\n",
    "FEATURE_LIST_FILENAME = \"my_feature_list.pkl\"\n",
    "\n",
    "def dump_classifier_and_data(clf, dataset, feature_list):\n",
    "    with open(CLF_PICKLE_FILENAME, \"w\") as clf_outfile:\n",
    "        pickle.dump(clf, clf_outfile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "        pickle.dump(dataset, dataset_outfile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"w\") as featurelist_outfile:\n",
    "        pickle.dump(feature_list, featurelist_outfile)\n",
    "\n",
    "def load_classifier_and_data():\n",
    "    with open(CLF_PICKLE_FILENAME, \"r\") as clf_infile:\n",
    "        clf = pickle.load(clf_infile)\n",
    "    with open(DATASET_PICKLE_FILENAME, \"r\") as dataset_infile:\n",
    "        dataset = pickle.load(dataset_infile)\n",
    "    with open(FEATURE_LIST_FILENAME, \"r\") as featurelist_infile:\n",
    "        feature_list = pickle.load(featurelist_infile)\n",
    "    return clf, dataset, feature_list\n",
    "\n",
    "def main():\n",
    "    ### load up student's classifier, dataset, and feature_list\n",
    "    clf, dataset, feature_list = load_classifier_and_data()\n",
    "    ### Run testing script\n",
    "    test_classifier(clf, dataset, feature_list)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
